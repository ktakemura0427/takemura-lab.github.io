<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications | Human Sensing Group</title>
    <link rel="stylesheet" href="./tailwind.min.css">
</head>
<body class="bg-white-100 text-gray-900">
    <!-- メニューを読み込む場所 -->
    <div id="header-placeholder"></div>

    <main class="container mx-auto px-6 py-10">
        <section>
            <h2 class="text-2xl font-bold mb-4">Publications</h2>
            <p class="mb-4">Below is a list of publications from the Human Sensing Group, showcasing our contributions to the field of human sensing technologies.</p>

            <details>
                <summary class="text-xl font-semibold mt-6 mb-2 text-red-600 cursor-pointer">Books and Book Chapters</summary>
                <ol class="list-decimal pl-6 mb-4">
                    <li>共著, ロボットテクノロジー, オーム社, ISBN978-4274210723.</li>
                    <li>Albert Causo, Kentaro Takemura, Jun Takamatsu, Tsukasa Ogasawara, Etsuko Ueda, Yoshio Matsumoto, "Predictive Tracking in Vision-based Hand Pose Estimation using Unscented Kalman Filter and Multi-viewpoint Cameras," In Human-Robot Interaction, edited by Daisuke Chugo, pp. 155-170, I-Tech, 2010.</li>
                    <li>奈良先端科学技術大学院大学OpenCVプログラミングブック制作チーム, OpenCVプログラミングブック, 毎日コミュニケーションズ, 2007.</li>
                </ol>
            </details>

            <details>
                <summary class="text-xl font-semibold mt-6 mb-2 text-red-600 cursor-pointer">Overview article</summary>
                <ol class="list-decimal pl-6 mb-4">
                    <li>高松 淳, Lotfi EI Hafi, 竹村 憲太郎, 小笠原 司，"角膜反射画像を用いた視線追跡と物体認識", 微小光学研究会機関誌, vol.36, no.3, pp.31-18, 2018.</li>
                    <li>竹村憲太郎，"装着型デバイスに向けたヒューマンセンシング(視線計測技術とアクティブ骨導音センシング)", 日本設計工学会誌, vol.53, no.11, pp.795-801, 2018.</li>
                </ol>
            </details>

            <details>
                <summary class="text-xl font-semibold mt-6 mb-2 text-red-600 cursor-pointer">Journal and Transaction</summary>
                <ol class="list-decimal pl-6 mb-4">
                    <li>Kazumi Chandrasiri and Kentaro Takemura, "Transferable Shape Estimation of Soft Pneumatic Actuators Based on Active Vibroacoustic Sensing," IEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 9849-9856, 2022. DOI: <a href="https://doi.org/10.1109/LRA.2022.3192630" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/LRA.2022.3192630</a></li>
                    <li>Koki Koshikawa, Takashi Nagamatsu, and Kentaro Takemura, "Model-based gaze estimation with transparent markers on large screens," Proceedings of the ACM on Human-Computer Interaction, vol. 6, no. 147, pp. 1-16, 2022. DOI: <a href="https://doi.org/10.1145/3530888" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3530888</a></li>
                    <li>長松隆, 菅野祐介, 竹村憲太郎, "キャリブレーションフリー視線計測手法の研究動向", ヒューマンインタフェース学会論文誌, vol. 23, no. 1, pp. 73-88, 2021. DOI: <a href="https://doi.org/10.11184/his.23.1_73" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.11184/his.23.1_73</a></li>
                    <li>佐々木政人, 長松隆, 竹村憲太郎, "偏光カメラシステムを用いた可視光Cross-Ratio Methodによる注視点推定", 画像電子学会誌, vol. 50, no. 1, 2021.</li>
                    <li>Shinichi Mikogai, B.D.C. Kazumi, and Kentaro Takemura, "Contact Point Estimation along Air Tube Based on Acoustic Sensing of Pneumatic System Noise," IEEE Robotics and Automation Letters, vol. 5, no. 3, pp. 4618-4625, 2020. DOI: <a href="https://doi.org/10.1109/LRA.2020.3002196" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/LRA.2020.3002196</a></li>
                    <li>山岸健太, 竹村憲太郎, "RGB-IRカメラを用いたハイブリッドな瞳孔・虹彩同時追跡", 計測自動制御学会論文集, vol. 55, no. 8, pp. 491-498, 2019. DOI: <a href="https://doi.org/10.9746/sicetr.55.491" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.9746/sicetr.55.491</a></li>
                    <li>加藤寛之, 竹村憲太郎, "能動的振動入力による手形状識別", 計測自動制御学会論文集, vol. 54, no. 1, pp. 62-68, 2018. DOI: <a href="https://doi.org/10.9746/sicetr.54.62" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.9746/sicetr.54.62</a></li>
                    <li>Yuki Uratsuji, Kentaro Takemura, Jun Takamatsu, and Tsukasa Ogasawara, "Mobility assistance system for an electric wheelchair using annotated maps," Advanced Robotics, vol. 29, no. 7, pp. 481-491, 2015. DOI: <a href="https://doi.org/10.1080/01691864.2015.1020070" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1080/01691864.2015.1020070</a></li>
                    <li>Kentaro Takemura, Kenji Takahashi, Jun Takamatsu, and Tsukasa Ogasawara, "Estimating 3-D Point-of-Regard in a Real Environment Using a Head-Mounted Eye-Tracking System," IEEE Transactions on Human-Machine Systems, vol. 44, no. 4, pp. 531-536, 2014. DOI: <a href="https://doi.org/10.1109/THMS.2014.2318324" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/THMS.2014.2318324</a></li>
                    <li>Kentaro Takemura, Tomohisa Yamakawa, Jun Takamatsu, and Tsukasa Ogasawara, "Estimation of a focused object using a corneal surface image for eye-based interaction," Journal of Eye Movement Research, vol. 7, no. 3, pp. 1-9, 2014. DOI: <a href="https://doi.org/10.16910/jemr.7.3.4" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.16910/jemr.7.3.4</a></li>
                    <li>Yutaka Kondo, Kentaro Takemura, Jun Takamatsu, and Tsukasa Ogasawara, "Gesture-centric Android System for Multi-party Human-Robot Interaction," Journal of Human-Robot Interaction, vol. 2, no. 1, pp. 133-151, 2013. DOI: <a href="https://doi.org/10.5898/JHRI.2.1.Kondo" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.5898/JHRI.2.1.Kondo</a></li>
                    <li>近藤豊, 竹村憲太郎, 高松淳, 小笠原司, "データベースとオンラインプラニングを統合した高速応答可能なジェスチャ生成", 日本ロボット学会, vol. 30, no. 9, pp. 899-906, 2012. DOI: <a href="https://doi.org/10.7210/jrsj.30.899" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.7210/jrsj.30.899</a></li>
                    <li>竹村憲太郎, 伊藤晃大, 高松淳, 小笠原司, "常時装着型ロボットインタフェースのためのアクティブ骨導音センシング", 日本ロボット学会誌, vol. 30, no. 8, pp. 745-751, 2012. DOI: <a href="https://doi.org/10.7210/jrsj.30.745" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.7210/jrsj.30.745</a></li>
                    <li>Tsuyoshi Suenaga, Kentaro Takemura, Jun Takamatsu, Tsukasa Ogasawara, "Data Communication Support for Reusability of RT-Components -Converter Classification and Prototype Supporting Tool-," Journal of Robotics and Mechatronics, vol. 24, no. 1, pp. 64-70, 2012. DOI: <a href="https://doi.org/10.20965/jrm.2012.p0064" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.20965/jrm.2012.p0064</a></li>
                    <li>竹村憲太郎, 小橋優司, 末永剛, 高松淳, 小笠原司, "頭部自由運動状況下における三次元注視点推定と注視軌跡の可視化手法", ヒューマンインタフェース学会論文誌, vol. 13, no. 1, pp. 83-90, 2011. DOI: <a href="https://doi.org/10.11184/his.13.1_83" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.11184/his.13.1_83</a></li>
                    <li>山本和樹, 上田悦子, 末永剛, 竹村憲太郎, 高松淳, 小笠原司, "ピアノ演奏における自然な手指動作CGの自動生成", 日本バーチャルリアリティ学会論文誌, vol. 15, no. 3, pp. 495-502, 2010. DOI: <a href="https://doi.org/10.18974/tvrsj.15.3_495" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.18974/tvrsj.15.3_495</a></li>
                    <li>荒木天外, 竹村憲太郎, 怡土順一, 松本吉央, 高松淳, 小笠原司, "汎用三次元環境地図を用いた移動ロボットナビゲーションのための地図生成", 日本ロボット学会誌, vol. 28, no. 1, pp. 106-111, 2010. DOI: <a href="https://doi.org/10.7210/jrsj.28.106" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.7210/jrsj.28.106</a></li>
                    <li>Albert Causo, Etsuko Ueda, Kentaro Takemura, Yoshio Matsumoto, Jun Takamatsu, and Tsukasa Ogasawara, "User-adaptable Hand Pose Estimation Technique for Human Robot Interaction," Journal of Robotics and Mechatronics, vol. 21, no. 6, pp. 739-748, 2009. DOI: <a href="https://doi.org/10.20965/jrm.2009.p0739" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.20965/jrm.2009.p0739</a></li>
                    <li>山城容一朗, 怡土順一, 竹村憲太郎, 松本吉央, 高松淳, 小笠原司, "ビューシーケンスに基づく照明変化に頑健な屋内外ナビゲーション", 日本ロボット学会誌, vol. 27, no. 7, pp. 768-773, 2009. DOI: <a href="https://doi.org/10.7210/jrsj.27.768" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.7210/jrsj.27.768</a></li>
                    <li>松本吉央, 怡土順一, 竹村憲太郎, 小笠原司, "リアルタイム顔・視線計測システムの開発と知的インタフェースへの応用", 情報処理学会論文誌コンピュータビジョンとイメージメディア, vol. 47, no. SIG15(CVIM16), pp. 10-21, 2006.</li>
                    <li>竹村憲太郎, 松本吉央, 小笠原司, "複数人の視線計測に基づく「場の注意」の推定", ヒューマンインタフェース学会論文誌, vol. 8, no. 1, pp. 185-194, 2006. </li>
                    <li>竹村憲太郎, 松本吉央, 小笠原司, "ドライバ行動解析のための非侵襲な注視計測システムの開発", 日本機械学会論文集, C編, vol. 71, no. 702, pp. 519-524, 2005. DOI: <a href="https://doi.org/10.1299/kikaic.71.519" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1299/kikaic.71.519</a></li>
                </ol>
            </details>

            <details>
                <summary class="text-xl font-semibold mt-6 mb-2 text-red-600 cursor-pointer">International Conference</summary>
                <ol class="list-decimal pl-6 mb-4">
                    <li>Kouki Komori and Kentaro Takemura, "Homography normalization enhanced to enable one-point user calibration for gaze estimation", in Proceedings of the 2025 Symposium on Eye Tracking Research and Applications (ETRA '25) Short Papers, No. 16, 2025.05. (poster), DOI: <a href="https://doi.org/10.1145/3715669.3723132" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3715669.3723132</a></li>
                    <li>Ayato Nakamura and Kentaro Takemura, "Extracting Corneal Reflection of Screen by High-Speed Control of Polarization," in Proceedings of the 2024 ACM International Conference on Interactive Surfaces and Spaces (ISS2024), pp. 33–36, 2024. (Poster), DOI: <a href="https://doi.org/10.1145/3696762.3698048" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3696762.3698048</a></li>
                    <li>Ratchanon Wattanaparinton, Kotaro Kitada, and Kentaro Takemura, "RFTIRTouch: Touch Sensing Device for Dual-sided Transparent Plane Based on Repropagated Frustrated Total Internal Reflection," in Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology (UIST2024), Article 113, 1–10. (Oral), DOI: <a href="https://doi.org/10.1145/3654777.3676363" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3654777.3676363</a></li>
                    <li>Tatsuya Kagemoto and Kentaro Takemura, "Event-Based Pupil Tracking Using Bright and Dark Pupil Effect," Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology (UIST2023), Article NO.:24, pp. 1-3, 2023.10. (Poster), DOI: <a href="https://doi.org/10.1145/3586182.3616657" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3586182.3616657</a></li>
                    <li>Natsuki Kawakami and Kentaro Takemura, "Error metric using correlation between binocular corneal images," 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2023.10. (Oral)</li>
                    <li>Gai Tanaka and Kentaro Takemura, "Eye Gaze Estimation Using Iris Segmentation Trained by Semi-Automated Annotation Work," 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2023.10. (Oral), DOI: <a href="https://doi.org/10.1109/smc53992.2023.10394400" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/smc53992.2023.10394400</a></li>
                    <li>Y. Kanai and K. Takemura, "Cooperative Eye Tracking and Localization Based on Corneal Imaging," in Proceedings of the 2023 IEEE/SICE International Symposium on System Integration (SII2023), pp. 1-6, 2023. (Oral), DOI: <a href="https://doi.org/10.1109/sii55687.2023.10039095" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/sii55687.2023.10039095</a></li>
                    <li>Ratchanon Wattanaparinton and Kentaro Takemura, "Vision-based tactile sensing using multiple contact images generated by re-propagated frustrated total internal reflections," 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 962-967, 2022. (Oral), DOI: <a href="https://doi.org/10.1109/smc53654.2022.9945094" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/smc53654.2022.9945094</a></li>
                    <li>Yutaro Inoue, Koki Koshikawa, and Kentaro Takemura, "Gaze Estimation with Imperceptible Marker Displayed Dynamically Using Polarization," in Proceedings of the 13th ACM Symposium on Eye Tracking Research & Applications (ETRA2022) Short Papers, No. 14, 2022.6. (poster), DOI: <a href="https://doi.org/10.1145/3517031.3529640" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3517031.3529640</a></li>
                    <li>Yuto Ito and Kentaro Takemura, "Estimating Focused Pedestrian using Smooth-Pursuits Eye Movements and Point Cloud toward Assistive System for Wheelchair," in Proceedings of 2021 IEEE International Conference on Systems, Man, and Cybernetics(SMC 2021), pp.404-410, 2021. (Oral), DOI: <a href="https://doi.org/10.1109/smc52423.2021.9659153" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/smc52423.2021.9659153</a></li>
                    <li>Kazumi Chandrasiri and Kentaro Takemura, "Estimating the Shape of Soft Pneumatic Actuators using Active Vibroacoustic Sensing," in Proceedings of the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021), pp. 7166-7171, 2021.9. (Oral), DOI: <a href="https://doi.org/10.1109/iros51168.2021.9636527" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/iros51168.2021.9636527</a></li>
                    <li>Kento Seida and Kentaro Takemura, "Eye Gaze Estimation using Imperceptible Marker Presented on High-Speed Display," in Proceedings of the 13th ACM Symposium on Eye Tracking Research & Applications (ETRA2021) Short Papers, No. 7, 2021.5. (poster), DOI: <a href="https://doi.org/10.1145/3448018.3458000" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3448018.3458000</a></li>
                    <li>Yuto Tamura and Kentaro Takemura, "Estimating Point-of-Gaze using Smooth Pursuit Eye Movements without Implicit and Explicit User-Calibration," in Proceedings of the 12th ACM Symposium on Eye Tracking Research & Applications (ETRA2020) Short Papers, No. 3, 2020.6. (poster), DOI: <a href="https://doi.org/10.1145/3379156.3391343" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3379156.3391343</a></li>
                    <li>Kouki Koshikawa, Masato Sasaki, Takamasa Utsu, and Kentaro Takemura, "Polarized Near-Infrared Light Emission for Eye Gaze Estimation," in Proceedings of the 12th ACM Symposium on Eye Tracking Research & Applications (ETRA2020) Short Papers, No. 2, 2020.6. (poster), DOI: <a href="https://doi.org/10.1145/3379156.3391342" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3379156.3391342</a></li>
                    <li>Yuto Tamura and Kentaro Takemura, "Estimating Focused Object using Smooth Pursuit Eye Movements and Interest Points in the Real World," The Adjunct Publication of the 32nd Annual Symposium on User Interface Software and Technology (UIST2019), pp. 21-23, 2019.10. (Poster), DOI: <a href="https://doi.org/10.1145/3332167.3357102" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3332167.3357102</a></li>
                    <li>Masato Sasaki, Takashi Nagamatsu, and Kentaro Takemura, "Cross-Ratio Based Gaze Estimation for Multiple Displays using a Polarization Camera," The Adjunct Publication of the 32nd Annual Symposium on User Interface Software and Technology (UIST2019), pp. 1-3, 2019.10. (Poster), DOI: <a href="https://doi.org/10.1145/3332167.3357095" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3332167.3357095</a></li>
                    <li>Ryusei Matsumoto and Kentaro Takemura, "Semantic 3D gaze mapping for estimating focused objects," in Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI2019), No. 49, 2019.10. (Poster), DOI: <a href="https://doi.org/10.1145/3338286.3344396" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3338286.3344396</a></li>
                    <li>Kenji Numakura and Kentaro Takemura, "Indoor human localization based on the corneal reflection of illumination," in Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI2019), No. 41, 2019.10. (Poster), DOI: <a href="https://doi.org/10.1145/3338286.3344388" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3338286.3344388</a><span class="text-red-600">【Best Poster Honorable Mention】</span></li>
                    <li>Takamasa Utsu and Kentaro Takemura, "Remote corneal imaging by integrating a 3D face model and an eyeball model," in Proceedings of the 11th ACM Symposium on Eye Tracking Research & Applications (ETRA2019), No. 44, 2019.6. (Poster), DOI: <a href="https://doi.org/10.1145/3314111.3319817" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3314111.3319817</a></li>
                    <li>Masato Sasaki, Takashi Nagamatsu, and Kentaro Takemura, "Screen corner detection using polarization camera for cross-ratio based gaze estimation," in Proceedings of the 11th ACM Symposium on Eye Tracking Research & Applications (ETRA2019), No. 24, 2019.6. (Oral), DOI: <a href="https://doi.org/10.1145/3314111.3319814" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3314111.3319814</a></li>
                    <li>Jun Ueda, Terese Martinez, Rohan Katoch, Kentaro Takemura, Reay Brown, "Direct Illumination of Micro Stent Implants for the Treatment of Glaucoma," 2019 ASME Design of Medical Devices (DMD). (Oral), DOI: <a href="https://doi.org/10.1115/dmd2019-3251" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1115/dmd2019-3251</a></li>
                    <li>Kenta Yamagishi and Kentaro Takemura, "A Hybrid Method for Remote Eye Tracking using RGB-IR Camera," in Proceedings of the 14th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, Vol.4, pp.591-596, 2019. (Poster), DOI: <a href="https://doi.org/10.5220/0007582700002108" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.5220/0007582700002108</a></li>
                    <li>Shintaro Kurihara and Kentaro Takemura, "Estimation of Hand Position and Biaxial Joint Angle by Vibration Emission," Proceedings of the 2019 IEEE/SICE International Symposium on System Integration(SII2019), pp.512-517, 2019. (Oral), DOI: <a href="https://doi.org/10.1109/sii.2019.8700384" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/sii.2019.8700384</a></li>
                    <li>Masato Sasaki, Takashi Nagamatsu, and Kentaro Takemura, "Cross-Ratio Based Gaze Estimation using Polarization Camera System," Proceedings of the 2018 ACM International Conference on Interactive Surfaces and Spaces (ISS2018), pp. 333-338, 2018. (Poster), DOI: <a href="https://doi.org/10.1145/3279778.3279909" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3279778.3279909</a></li>
                    <li>Ryo Kamoshida, and Kentaro Takemura, "Head pose classification by using body-conducted sound," Proceedings of the 31st Annual Symposium on User Interface Software and Technology (UIST2018), pp. 39-41.2018.10. (Poster), DOI: <a href="https://doi.org/10.1145/3266037.3266094" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3266037.3266094</a></li>
                    <li>Kentaro Takemura, Euisun Kim and Jun Ueda, Individualized Inter-Stimulus Interval Estimation for Neural Facilitation in Human Motor System: A Particle Filtering Approach, ASME 2018 Dynamic Systems and Control Conference,  2018.10. (Oral), DOI: <a href="https://doi.org/10.1115/dscc2018-9155" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1115/dscc2018-9155</a></li>
                    <li>Nobuhiro Funato, and Kentaro Takemura, "Estimating three-axis contact force for fingertip by emitting vibration actively," Proceedings of the 2017 IEEE International Conference on Robotics and Biomimetics(ROBIO2017), pp. 406-411.2017.(Oral), DOI: <a href="https://doi.org/10.1109/robio.2017.8324451" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/robio.2017.8324451</a></li>
                    <li>Nobuhiro Funato, and Kentaro Takemura, "Grip Force Estimation by Emitting Vibration," Proceedings of the 30th Annual Symposium on User Interface Software and Technology (UIST2017), pp. 141-142.2017.(Poster), DOI: <a href="https://doi.org/10.1145/3131785.3131829" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/3131785.3131829</a></li>
                    <li>Kenta Yamagishi, and Kentaro Takemura, "A hybrid eye-tracking method using multispectral camera," Proceedings of 2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp.1529-1534, 2017. (Oral), DOI: <a href="https://doi.org/10.1109/smc.2017.8122831" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/smc.2017.8122831</a></li>
                    <li>Sara Suda, Kenta Yamagishi, and Kentaro Takemura, "User Calibration-free Method using Corneal Surface Image for Eye Tracking," Proceedings of the 12th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications – Volume 6: VISAPP, pp.67-73, 2017. (Oral), DOI: <a href="https://doi.org/10.5220/0006100100670073" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.5220/0006100100670073</a></li>
                    <li>Nobuhiro Funato, and Kentaro Takemura, "Estimating Contact Force of Fingertip and Providing Tactile Feedback Simultaneously," Proceedings of the 29th Annual Symposium on User Interface Software and Technology (UIST2016), pp. 195-196.2016. (Poster), DOI: <a href="https://doi.org/10.1145/2984751.2984766" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/2984751.2984766</a></li>
                    <li>Hiroyuki Kato, and Kentaro Takemura, "Hand pose estimation based on active bone-conducted sound sensing." Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct. ACM,  pp. 109-112, 2016. (Poster), DOI: <a href="https://doi.org/10.1145/2968219.2971403" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/2968219.2971403</a></li>
                    <li>Etsuko Ueda, Kenichi Iida, Kentaro Takemura, Takayuki Nakamura, Masanao Koeda "Identification of Gracefulness Feature Parameters for Hand-Over Motion," 18th International Conference, HCI International 2016, pp.115-124, 2016.7. (Oral)</li>
                    <li>Lotfi El Hafi, Kentaro Takemura, Jun Takamatsu, Tsukasa Ogasawara, "Model-Based Approach for Gaze Estimation from Corneal Imaging Using a Single Camera," in Proceedings of 2015 IEEE/SICE International Symposium on System Integration (SII2015), pp.88 – 93, 2015.12. (Oral), DOI: <a href="https://doi.org/10.1109/sii.2015.7404959" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/sii.2015.7404959</a></li>
                    <li>Y. Okawa, and K. Takemura: "Haptic-enabled Active Bone-Conducted Sound Sensing," Proceedings of the 28th ACM Symposium on User Interface Software and Technology (UIST2015),  pp. 87-88, 2015.11. (Poster), DOI: <a href="https://doi.org/10.1145/2815585.2815732" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/2815585.2815732</a></li>
                    <li>Ochiai Yuya, Kentaro Takemura, Atsutoshi Ikeda, Jun Takamatsu, and Tsukasa Ogasawara, "Remote Control System for Multiple Mobile Robots Using Touch Panel Interface and Autonomous Movility," IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2014), pp.3272- 3277,   2014.9. (Oral), DOI: <a href="https://doi.org/10.1109/iros.2014.6943017" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/iros.2014.6943017</a></li>
                    <li>Kentaro Takemura, Shunki Kimura, and Sara Suda, "Estimating point-of-regard using corneal surface image,"  Proceedings of ACM Symposium on Eye-Tracking Research & Applications (ETRA2014), pp.251-254, 2014.3. (Poster), DOI: <a href="https://doi.org/10.1145/2578153.2578197" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/2578153.2578197</a></li>
                    <li>Jun Takamatsu, Yutaka Kondo, Kentaro Takemura, Akihiko Yamaguchi, Tsukasa Ogasawara, "Human-Robot Interaction by an Actroid Robot Based on Natural Motion Database," 2013 Japan-Korea Workshop on Information, Communication and Robotics Technology Innovation for Population Aging, 2013. (Oral)</li>
                    <li>Kentaro Takemura, Tomohisa Yamakawa, Jun Takamatsu, Tsukasa Ogasawara, "Estimating Focused Object using Corneal Surface Image for Eye-based Interaction," Proceedings of the 3rd International Workshop on Pervasive Eye Tracking and Mobile Eye-Based Interaction, 2013.8. [PDF][Slides] (Oral)</li>
                    <li>T. Tanaka, T. Tsuduki, E. Ueda, K. Takemura & T. Nakamura, "Modeling of graceful motions: determining characteristics of graceful motions from handover motion,"Proceedings of the 16th International Conference on Computational Methods and Experimental Measurements, pp.453-465, 2013.7. (Oral)</li>
                    <li>Akihiko Yamaguchi, Shiori Sato, Kentaro Takemura, Jun Takamatsu, and Tsukasa Ogasawara: Style Translation Filter to Change Attribute of Motion, Proceedings of  the 12th IEEE-RAS International Conference on Humanoid Robots, pp.660-665, 2012.12. (Oral)</li>
                    <li>Y. Hieida, T. Suenaga, K. Takemura, J. Takamatsu and T. Ogasawara: "Real-time Scan-Matching Using L0-norm Minimization Under Dynamic Crowded Environment," Proceedings of the 4th IROS Workshop on Planning, Perception and Navigation for Intelligent Vehicles , 2012.10. (Oral)</li>
                    <li>Yutaka Kondo, Kentaro Takemura, Jun Takamatsu, Tsukasa Ogasawara, "Body Gesture Classification based on Bag-of-features in Frequency Domain of Motion," Proceedings of the 21st IEEE Int. Symp. on Robot and Human Interactive Communication (RO-MAN2012),pp.386 – 391,2012.9.(Oral), DOI: <a href="https://doi.org/10.1109/roman.2012.6343783" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/roman.2012.6343783</a></li>
                    <li>Emarc Magtanong, Akihiko Yamaguchi, Kentaro Takemura, Jun Takamatsu, and Tsukasa Ogasawara: "Inverse Kinematics Solver for Android Faces with Elastic Skin," Latest Advances in Robot Kinematics, pp. 181-188, 2012.6. (Oral), DOI: <a href="https://doi.org/10.1007/978-94-007-4620-6_23" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1007/978-94-007-4620-6_23</a></li>
                    <li>Yutaka Kondo, Kentaro Takemura, Jun Takamatsu, Tsukasa Ogasawara: "Planning Body Gesture of Android for Multi-person Human-Robot Interaction," Proceedings of IEEE Int. Conf. of Robotics and Automation (ICRA2012), pp. 3897-3902, 2012.5. (Oral), DOI: <a href="https://doi.org/10.1109/icra.2012.6224903" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/icra.2012.6224903</a></li>
                    <li>K. Takemura, A. Ito, J. Takamatsu, and T. Ogasawara: "Active Bone-Conducted Sound Sensing for Wearable Interfaces," Proceedings of the 24th ACM Symposium on User Interface Software and Technology (UIST2011),  pp. 53-54, 2011.10.(Poster), DOI: <a href="https://doi.org/10.1145/2046396.2046419" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/2046396.2046419</a></li>
                    <li>S. Asano, T. Suenaga, K. Takemura, Y. Matsumoto, J. Takamatsu, and T. Ogasawara: "6-DOF Head Pose Estimation in Wider Range and Space by Integrating Multi-Camera Observation," Proceedings of ICRA 2011 Workshop on Measuring and Understanding Human Movements and Emotions, 2011.5. (Oral)</li>
                    <li>Y. Kondo, M. Kawamura, K. Takemura, J. Takamatsu, and T. Ogasawara: "Gaze Motion Planning for Android Robot," Proceedings of the 6th ACM/IEEE International Conference on Human Robot Interaction (HRI2011), pp.171-172, 2011.3. (Oral)</li>
                    <li>Y. Kondo, K. Takemura, J. Takamatsu, and T. Ogasawara: "Multi-person Human-Robot Interaction System for Android Robot," Proceedings of the 2010 IEEE/SICE International Symposium on System Integration (SII2010), pp.176-181, 2010.12. (Oral), DOI: <a href="https://doi.org/10.1109/sii.2010.5708321" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/sii.2010.5708321</a></li>
                    <li>K. Yamamoto, E. Ueda, T. Suenaga, K. Takemura, J. Takamatsu, and T. Ogasawara: "Generating Natural Hand Motion in Playing a Piano," Proceedings of 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2010), pp. 3513 – 3518, 2010.10. (Oral)</li>
                    <li>T. Suenaga, K. Takemura, J. Takamatsu, and T. Ogasawara: "Data Communication Support for Reusability of RT-Components -Converter Classification and Prototype Supporting Tool-," Proceedings of International Conference on Advanced Mechatronics 2010 (ICAM 2010), pp.516-521, 2010.10. (Oral)</li>
                    <li>Y. Kondo, K. Takemura, J. Takamatsu, and T. Ogasawara: "Smooth Human-Robot Interaction by Interruptible Gesture Planning," Proceedings of the 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM2010), pp. 213-218, 2010.10. (Oral)</li>
                    <li>S. Hirose, T. Suenaga, K. Takemura, R. Kawakami, J. Takamatsu, and T. Ogasawara: "Surface Color Estimation Based on Inter- and Intra-Pixel Relationships in Outdoor Scenes," Proceedings of 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR2010), pp.271-278, 2010.6. (Oral), DOI: <a href="https://doi.org/10.1109/CVPR.2010.5540039" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/CVPR.2010.5540039</a></li>
                    <li>K. Takemura, A. Araki, J. Ido, Y. Matsumoto, J. Takamatsu, and T. Ogasawara: "Generating Individual Maps from Universal Map for Heterogeneous Mobile Robots," Proceedings of IEEE International Conference of Robotics and Automation(ICRA2010), pp.3460-3465, 2010.5. (Oral)</li>
                    <li>K. Takemura, Y. Kohashi, T. Suenaga, J. Takamatsu, and T. Ogasawara: "Estimating 3D Point-of-regard and Visualizing Gaze Trajectories under Natural Head Movements," Proceedings of ACM Symposium on Eye-Tracking Research & Applications (ETRA2010), pp.157-160, 2010.3. (Oral), DOI: <a href="https://doi.org/10.1145/1743666.1743700" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1145/1743666.1743700</a></li>
                    <li>Y. Yamagi, J. Ido, K. Takemura, Y. Matsumoto, J. Takamatsu, and T. Ogasawara: "View-Sequence Based Indoor/Outdoor Navigation Robust to Illumination Changes," Proceedings of the 2009 IEEE/RSJ International Conference on Intelligent Robotics and Systems (IROS2009), pp. 1229-1234, 2009.10 (Oral)</li>
                    <li>A. Causo, M. Matsuo, E. Ueda, K. Takemura, Y. Matsumoto, J. Takamatsu and T. Ogasawara: "Hand Pose Estimation using Voxel-based Individualized Hand Model," Proceedings of the 2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM2009), pp.451-456, 2009.7. (Oral)</li>
                    <li>Y. Kurita, J. Kobayashi, T. Suenaga, K. Takemura, Y. Matsumoto, and T. Ogasawara: "Personal Identification and Visualization of Relationships by using Human Trajectories," Proceedings of IEEE International Conference on Robotics and Biomimetics (ROBIO2009), pp.548-553, 2009.2. (Oral)</li>
                    <li>K. Takemura, Y. Matsumoto, and T. Ogasawara: "Estimation of Group Attention for Automated Camerawork," Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS2008), pp.2317-2322, 2008.9. (Oral)</li>
                    <li>K. Takemura, Y. Matsumoto, and T. Ogasawara: "Target Selection for Controlling Home Appliances Based on Gaze Measurement Technology," Proceedings of the 12th International Conference on Human-Computer-Interaction International (HCII2007), pp.504-508, 2007.7. (Poster)</li>
                    <li>K. Mitsui, H. Igaki, M. Nakamura, K. Matsumoto, and K. Takemura, "Exploiting Eye Gaze Information for Operating Services in Home Network System," Proceedings of  the 2006 International Symposium on Ubiquitous Computing Systems, Vol.LNCS4239, pp.13-27, 2006.9. (Oral), DOI: <a href="https://doi.org/10.1007/11941354_2" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1007/11941354_2</a></li>
                    <li>K. Takemura, Y. Matsumoto, and T. Ogasawara: "Estimation of Focus of Attention of Multiple People for Video Conferencing," Presented at CHI 2005’s alt.chi Session (CHI2005), 2005.4. (Oral)</li>
                    <li>K. Takemura, H. Minamide, Y. Matsumoto, and T. Ogasawara: "What You Look at Is What You Control:  A Universal Remote Control Based on Gaze Measurement Technology," Proceedings of the 1st IEEE Technical Exhibition Based Conference on Robotics and Automation (TExCRA2004), 2004.11. (Poster)</li>
                    <li>Y. Matsumoto, J. Ido, K. Takemura, M. Koeda, and T. Ogasawara: "Portable Facial Information Measurement System and Its Application to Human Modeling and Human Interfaces," Proceedings of the  6th IEEE  International Conference on Face and Gesture Recognition (FG2004), pp.475-480, 2004.5. (Oral)</li>
                    <li>K. Takemura, J. Ido, Y. Matsumoto, and T. Ogasawara: "Development of Non-Contact Drive Monitoring System for Advanced Safety Vehicle," Proceedings of  IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM2003), pp.1119-1122, 2003.7. (Oral)</li>
                    <li>K. Takemura, J. Ido, Y. Matsumoto, and T. Ogasawara: "Drive Monitoring System Based on Non-Contact Measurement System of Driver’s Focus of Visual Attention," Proceedings of IEEE Intelligent Vehicles Symposium (IV2003), pp.581-586, 2003.6. (Oral), DOI: <a href="https://doi.org/10.1109/iv.2003.1212883" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/iv.2003.1212883</a></li>
                    <li>J. Ido, K. Takemura, Y. Matsumoto, and T. Ogasawara: "Robotic Receptionist ASKA:  A Research Platform for Human-Robot Interaction," Proceedings of IEEE International Workshop on Robot and Human Interactive Communication (ROMAN2002), pp.306-311, 2002.6. (Oral), DOI: <a href="https://doi.org/10.1109/ROMAN.2002.1045635" class="text-blue-600 hover:text-blue-800 visited:text-purple-600">10.1109/ROMAN.2002.1045635</a></li>
                </ol>
            </details>                                    
            <details>
                <summary class="text-xl font-semibold mt-6 mb-2 text-red-600 cursor-pointer">Domestic Conference</summary>
                <ol class="list-decimal pl-6 mb-4">
                    <li>北田鼓太郎，ワッタナパリントンラッチャノン，竹村憲太郎："漏れ全反射の再伝播を用いたタッチデバイス"，ロボティクスメカトロニクス講演会2025，1A2-T05，2025年6月5日，(山形県・山形市)</li>
                    <li>小森紅輝，竹村憲太郎："ワンポイントキャリブレーションが可能な Homography Normalization ベースの視線計測手法"，ロボティクスメカトロニクス講演会2025，1A2-T06，2025年6月5日，(山形県・山形市)</li>
                    <li>中村綺斗，竹村憲太郎："不知覚な背景提示と液晶の高速制御による偏光を用いた視線計測技術"，第25回 計測自動制御学会 システムインテグレーション部門講演会，1D2-11，2024年12月18日，（岩手県・盛岡市）<span class="text-red-600">【優秀講演賞】</span></li>
                    <li>影本竜也，竹村憲太郎："イベントベース瞳孔追跡を用いた眼球運動測定"，第25回 計測自動制御学会 システムインテグレーション部門講演会，1D4-02，2024年12月18日，（岩手県・盛岡市）<span class="text-red-600">【優秀講演賞】</span></li>
                    <li>東賢志，竹村憲太郎："歪曲マーカを用いたモデルベース視線計測"，ロボティクスメカトロニクス講演会2024，1P2-R07，2024年5月30日，(栃木県・宇都宮市)</li>
                    <li>イムスックアディソーン，竹村憲太郎:"角膜の接平面画像を用いた視覚欠損の可視化"，ロボティクスメカトロニクス講演会2024，1P2-R06，2024年5月30日，(栃木県・宇都宮市)</li>
                    <li>河上奈月，竹村憲太郎："角膜イメージングを用いた暗黙的キャリブレーションの基礎的検討"，ロボティクスメカトロニクス講演会2024，1P2-R05，2024年5月30日，(栃木県・宇都宮市)</li>
                    <li>影本竜也，竹村憲太郎："イベントベースによる明・暗瞳孔法を用いた瞳孔追跡"，第24回 計測自動制御学会 システムインテグレーション部門講演会，1G6-12，2023年12月14日，(新潟県，新潟市) <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>河上奈月，竹村憲太郎："両眼角膜イメージングによる３次元注視点の誤差評価"，第24回 計測自動制御学会 システムインテグレーション部門講演会，1G1-14，2023年12月14日，(新潟県，新潟市) <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>田中凱，竹村憲太郎："照明変化に頑健な虹彩を基準としたモデルベース視線計測"，第24回 計測自動制御学会 システムインテグレーション部門講演会，1G1-09，2023年12月14日，(新潟県，新潟市)</li>
                    <li>ワッタナパリントンラッチャノン，竹村憲太郎："再伝播する漏れ全反射の物理モデルを用いた接触位置推定"，第24回 計測自動制御学会 システムインテグレーション部門講演会，1G1-08，2023年12月14日，(新潟県，新潟市)</li>
                    <li>河上奈月，竹村憲太郎："両眼の角膜反射像による3次元注視点の評価"，ロボティクスメカトロニクス講演会2023，1P1-H04，2023年6月29日，(愛知県・名古屋市)</li>
                    <li>ワッタナパリントンラッチャノン，竹村憲太郎："漏れ全反射の再伝播を用いた接触位置推定"，第23回 計測自動制御学会 システムインテグレーション部門講演会，3P3-D05，2022年12月16日，(千葉県，千葉市) <span class="text-red-600">【優秀講演賞】【部門若手奨励賞】</span></li>
                    <li>井上勇太郎，竹村憲太郎："視線計測のための液晶を用いた不可視マーカの動的再配置"，第23回 計測自動制御学会 システムインテグレーション部門講演会，3P3-D04，2022年12月16日，(千葉県，千葉市)</li>
                    <li>金井祐樹，竹村憲太郎："屋内照明の角膜反射像とIMUを用いた位置推定"，ロボティクスメカトロニクス講演会2022，R07-2P1，2022年6月3日，(北海道・札幌市)</li>
                    <li>伊藤雄仁，竹村憲太郎："視線計測装置と LiDAR 間の幾何的な拘束が不要な歩行者に対する注視判定手法"，第22回 計測自動制御学会 システムインテグレーション部門講演会，1B1-04，2021年12月15日，(オンライン開催)</li>
                    <li>清田健登，竹村憲太郎："高速液晶ディスプレイを用いた不可視な基準点の提示による注視点推定"，第22回 計測自動制御学会 システムインテグレーション部門講演会，1B1-05，2021年12月15日，(オンライン開催) <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>越川洸希，佐々木政人，宇都貴将，竹村憲太郎："視線計測のための偏光近赤外線の照射による角膜反射像の識別"，第21回 計測自動制御学会 システムインテグレーション部門講演会，2B3-14，2020年12月17日，(オンライン開催) <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>佐々木政人，長松隆，竹村憲太郎："角膜表面に反射したディスプレイ像の偏光情報を用いたモデルベースの注視点推定"，第21回 計測自動制御学会 システムインテグレーション部門講演会，2B2-05，2020年12月17日，(オンライン開催) <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>佐々木政人，長松隆，竹村憲太郎："偏光Cross-Ratio Methodによる複数画面に対する注視点推定"，第38回 日本ロボット学会学術講演会，2D1-01，2020年10月10日，(オンライン開催)</li>
                    <li>チャンドラシリカズミ，竹村憲太郎："アクティブ音響センシングを用いた空気圧アクチュエータの形状推定"，第20回 計測自動制御学会 システムインテグレーション部門講演会，3D2-10，2019年12月14日，（香川県・高松市）</li>
                    <li>御子貝真一，竹村憲太郎："アクティブ音響センシングを用いたチューブの接触位置推定"，第20回 計測自動制御学会 システムインテグレーション部門講演会，3D2-09，2019年12月14日，（香川県・高松市）</li>
                    <li>佐々木政人，長松隆，竹村憲太郎："偏光カメラを用いた Cross-Ratio Method による注視点推定"，第20回 計測自動制御学会 システムインテグレーション部門講演会，1C1-06，2019年12月12日，（香川県・高松市） <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>田村祐人，竹村憲太郎："滑動性眼球運動を用いた実空間での注視対象推定"，第20回 計測自動制御学会 システムインテグレーション部門講演会，1C1-05，2019年12月12日，（香川県・高松市） <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>沼倉健二，竹村憲太郎："角膜上に映る照明情報を用いた人の位置推定"，ロボティクスメカトロニクス講演会2019，2P1-J05，2019年6月7日，(広島県・広島市)</li>
                    <li>松本龍晟，竹村憲太郎："複数人の注視行動理解に向けたセマンティックマップによる三次元注視点推定"，ロボティクスメカトロニクス講演会2019，2P1-J04，2019年6月7日，(広島県・広島市)</li>
                    <li>佐々木政人，竹村憲太郎："偏光カメラシステムによるディスプレイ反射領域検出を用いた可視光 Cross-Ratio Method"，ロボティクスメカトロニクス講演会2019，2P1-J03，2019年6月7日，(広島県・広島市)</li>
                    <li>宇都貴将，竹村憲太郎："3次元顔モデルを用いた非装着型角膜イメージング法"，第19回 計測自動制御学会 システムインテグレーション部門講演会，3D2-10，2018年12月15日，（大阪府・大阪市） <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>畠中亮太，上田悦子，飯田賢一，竹村憲太郎，小枝正直，中村恭之："1D2-02  古典舞踊動作が作る曲面形状の「複雑さ」が印象評価に及ぼす影響", 1D2-02, 2018年12月13日，（大阪府・大阪市）</li>
                    <li>鴨志田亮，竹村憲太郎："体導音を用いた頭部姿勢識別"，第19回 計測自動制御学会 システムインテグレーション部門講演会，1B3-08，2018年12月13日，（大阪府・大阪市）</li>
                    <li>佐々木政人，竹村憲太郎："ディスプレイ反射像を用いた可視光Cross-Ratio Methodによる注視点推定"，ロボティクスメカトロニクス講演会2018，2P1-A06，2018年6月5日，(福岡県・北九州市)</li>
                    <li>栗原慎太郎，竹村憲太郎："アクティブ骨導音センシングを用いたサポートベクトル回帰による二軸性関節の角度推定"，第18回 計測自動制御学会 システムインテグレーション部門講演会，3A3-10，2017年12月22日，(宮城県・仙台市)</li>
                    <li>畠中亮太，上田悦子，飯田賢一，竹村憲太郎，小枝正直，中村恭之："古典舞踊動作の腕軌道が作る曲面形状に着目した優美さ特徴抽出"，第18回 計測自動制御学会 システムインテグレーション部門講演会，2B3-05，2017年12月21日，(宮城県・仙台市)</li>
                    <li>舩戸恒宏，竹村憲太郎："能動的振動入力による３軸指先接触力推定"，第18回 計測自動制御学会 システムインテグレーション部門講演会，1B3-08，2017年12月20日，(宮城県・仙台市)</li>
                    <li>加藤寛之，竹村憲太郎："能動的振動入力を用いた指先接触離脱判定"，第18回 計測自動制御学会 システムインテグレーション部門講演会，1B3-07，2017年12月20日，(宮城県・仙台市)</li>
                    <li>山岸健太，竹村憲太郎："RGB-IRカメラを用いた瞳孔・虹彩同時追跡 -極座標変換を用いた虹彩の自動検出-"，第18回 計測自動制御学会 システムインテグレーション部門講演会，1C2-10，2017年12月20日，(宮城県・仙台市)</li>
                    <li>須藤美和，山岸健太，竹村憲太郎："非装着型角膜イメージング法のための３次元眼球モデルを用いた虹彩追跡"，第18回 計測自動制御学会 システムインテグレーション部門講演会，1C2-08，2017年12月20日，(宮城県・仙台市)</li>
                    <li>舩戸恒宏，竹村憲太郎："能動的振動入力による把持力推定"，第35回 日本ロボット学会学術講演会，1J3-04，2017年9月12日，(埼玉県・川越市)</li>
                    <li>山岸健太，竹村憲太郎："眼球回旋点の移動を考慮した瞳孔・虹彩同時追跡"，The 23rd Symposium on Sensing via Image Information(SSII2017)，IS2-15，2017年6月8日，(神奈川県・横浜市)</li>
                    <li>品川慶樹，山岸健太，須田沙良，竹村憲太郎："３次元眼球モデルを用いたCross-Ratio Methodによる注視点推定"，ロボティクスメカトロニクス講演会2017，2P1-M07，2017年5月12日，(福島県・郡山市)</li>
                    <li>畠中亮太，上田悦子，飯田賢一，竹村憲太郎，小枝正直，中村恭之："優美さ定量化のための古典舞踊動作における腕軌道と手先動作解析"，ロボティクスメカトロニクス講演会2017，1P2-L01，2017年5月12日，(福島県・郡山市)</li>
                    <li>加藤寛之，竹村憲太郎："能動的振動入力による触覚フィードバック可能な手形状推定"，第17回 計測自動制御学会 システムインテグレーション部門講演会，1A1-2，2016 <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>中村匠，飯田賢一，竹村憲太郎，小枝正直，中村恭之，上田悦子："古典舞踊動作の手先軌道に着目した優美さの定量化"，第17回 計測自動制御学会 システムインテグレーション部門講演会，2N2-2，2016 <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>栗原慎太郎，竹村憲太郎："ファントムセンセーションが可能な能動的振動入力による関節角度推定"，第17回 計測自動制御学会 システムインテグレーション部門講演会，3B4-2，2016</li>
                    <li>竹村憲太郎，大川裕也，加藤寛之："アクティブ骨導音センシングを用いた下肢単関節及び上肢複数関節の角度推定"，第34回 日本ロボット学会学術講演会，2W2-02，2016年9月8日，(山形県・山形市)</li>
                    <li>中村匠，飯田賢一，竹村憲太郎，小枝正直，中村恭之，上田悦子："観客視点を考慮した古典舞踊動作における手先軌道の解析"，ロボティクスメカトロニクス講演会2016，2P1-12a4，2016年6月10日，(神奈川県・横浜市)</li>
                    <li>高瀬悠太，加藤寛之，竹村憲太郎："能動的な振動入力による把持物体推定"，ロボティクスメカトロニクス講演会2016，1A2-12a6，2016年6月9日，(神奈川県・横浜市)</li>
                    <li>山岸健太，竹村憲太郎："2CCDカメラを用いた瞳孔・虹彩同時追跡"，ロボティクスメカトロニクス講演会2016，1A2-12b5，2016年6月9日，(神奈川県・横浜市)</li>
                    <li>舩戸恒宏，竹村憲太郎："アクティブ骨導音センシングを用いた指先接触力推定"，ロボティクスメカトロニクス講演会2016，1P1-13a6，2016年6月9日，(神奈川県・横浜市)</li>
                    <li>大川裕也，竹村憲太郎："触覚フィードバックが可能な振動による関節角度推定"，第23回インタラクティブシステムとソフトウェアに関するワークショップ(WISS2015)招待デモ，2-R02，2015年12月3日，(大分県)</li>
                    <li>町田貴紀，須田沙良，竹村憲太郎："角膜表面反射画像を用いた頭部・眼球運動推定"，第16回計測自動制御学会システムインテグレーション部門講演会，1E2-5，2015.</li>
                    <li>上田悦子，中村恭之，飯田賢一，小枝正直，竹村憲太郎："アジア古典舞踊動作における表現の差異"，第16回計測自動制御学会システムインテグレーション部門講演会，2A2-6，2015.</li>
                    <li>須田沙良，町田貴紀，竹村憲太郎："両眼モデルを用いた角膜表面反射画像の展開"，ヒューマンインタフェースシンポジウム2015，1511P，2015年9月2日，(北海道・函館市)</li>
                    <li>大川裕也，竹村憲太郎："アクティブ骨導音センシングによる把持制御と把持状態フィードバック"，ロボティクスメカトロニクス講演会2015，1P1-l01，2015年5月18日，(京都府・京都市)</li>
                    <li>須田沙良，竹村憲太郎："視軸を考慮した角膜表面反射画像展開"，第15回 計測自動制御学会 システムインテグレーション部門講演会, 3G3-4，2014.</li>
                    <li>竹村憲太郎，須田沙良："日常生活における角膜表面反射画像を用いた視野映像の生成"，第32回日本ロボット学会学術講演会，1C3-03，2014.</li>
                    <li>島田健史，池田篤俊，竹村憲太郎，高松淳，小笠原司："一人称視点を用いた調理作業記録システムの構築"，第32回日本ロボット学会学術講演会，1C3-05，2014.</li>
                    <li>加藤寛之，竹村憲太郎，アクティブ骨導音センシングを用いた手形状推定，第32回日本ロボット学会学術講演会，3E2-03, 2014年9月6日, (九州・福岡市)</li>
                    <li>大川裕也，竹村憲太郎："触覚フィードバックが可能なアクティブ骨導音センシング"，ロボティクスメカトロニクス講演会2014，3P1-N01，2014年5月28日，(富山県・富山市)</li>
                    <li>木村孝広，吉川雅博，竹村憲太郎，高松淳，小笠原司："環境の形状情報を付加した人間の動作分類に基づく3次元セマンティックマップの生成", ロボティクスメカトロニクス講演会2014, 3P1-I02, 2014.</li>
                    <li>田辺雅人，吉川雅博，竹村憲太郎，高松淳，小笠原司: "インターバル3次元形状計測からの環境変化の識別"，ロボティクスメカトロニクス講演会2014, 3P1-I02, 2014.</li>
                    <li>竹村憲太郎："虹彩のモデルベース追跡による角膜表面反射画像展開"，第14回計測自動制御学会システムインテグレーション部門講演会，2A2-1, 2013.</li>
                    <li>田辺雅人，竹村憲太郎，吉川雅博，高松淳，小笠原司："インターバル3次元計測からの環境変化の検出"，第14回計測自動制御学会システムインテグレーション部門講演会，2K3-4, 2013.</li>
                    <li>竹村憲太郎："角膜表面反射画像と環境画像を併用したキャリブレーションフリー視線計測手法"，第31回日本ロボット学会学術講演会，1E1-04, 2013. <span class="text-red-600">【研究奨励賞】</span></li>
                    <li>高松淳，竹村憲太郎，小笠原司，工藤由貴子，斎藤悦子："QoL向上のための人・ロボット協調とマネージメントの可能性"，第31回日本ロボット学会学術講演会，1N1-06, 2013.</li>
                    <li>浦辻勇輝，竹村憲太郎，高松淳，小笠原司："QoL向上のためのアノテーション付き地図を利用したモビリティ支援"，第31回日本ロボット学会学術講演会，1N1-07, 2013.</li>
                    <li>落合佑哉，竹村憲太郎，高松淳，小笠原司："タッチ入力と自律移動を利用した複数移動ロボットの同時遠隔操作システム"，第31回日本ロボット学会学術講演会，3H2-06, 2013.</li>
                    <li>竹村憲太郎，小笠原司："常時装着型角膜表面反射画像撮像装置の開発"，ロボティクスメカトロニクス講演会2013，2A2-G04，2013.</li>
                    <li>木村孝広, 勝山貴史, 竹村憲太郎, 高松淳, 小笠原司: "移動ロボットを用いたユーザの姿勢情報分類及びマッピング", ロボティクスメカトロニクス講演会2013, 1P1-H06, 2013.</li>
                    <li>竹村憲太郎，山川智久，高松淳，小笠原司："角膜表面反射画像を用いた注視対象推定"，第13回計測自動制御学会システムインテグレーション部門講演会(SI2012), 3F3-5, pp.2235-2236, 2012. <span class="text-red-600">【優秀講演賞】</span></li>
                    <li>田辺雅人, 木村孝広, 馬場浩平, 大下将宗, 吉山友明, 勝山貴史, 田中康之, 竹村憲太郎, 小笠原司："屋外動的環境下における注視対象推定 色付き三次元点群を用いた移動物体検出", 第13回計測自動制御学会システムインテグレーション部門講演会(SI2012), 3F1-2, pp.2178-2179, 2012.</li>
                    <li>竹村憲太郎, 小笠原司: "アクティブ骨導音センシングによるMP関節角度推定", 第30回日本ロボット学会学術講演会, RSJ2012AC3D1-6, 2012年9月19日, (北海道・札幌市)</li>
                    <li>山川智久, 竹村憲太郎, 高松淳, 小笠原司: "角膜表面反射画像を用いた特定物体認識", 第30回日本ロボット学会学術講演会, RSJ2012AC2J1-3, 2012.</li>
                    <li>勝山貴史, 竹村憲太郎, 高松淳, 小笠原司: "人間の動作により意味付けされた3次元セマンティックマップの生成", 第30回日本ロボット学会学術講演会, RSJ2012AC2N3-6, 2012.</li>
                    <li>浦辻勇輝, 竹村憲太郎, 高松淳, 小笠原司: "電動車椅子のための関心度マップを用いたDynamic Shared Control", 第30回日本ロボット学会学術講演会,RSJ2012AC1K2-7, 2012.</li>
                    <li>田中康之, 竹村憲太郎, 高松淳, 小笠原司: "ポイントクラウドを対象としたBag-of-featuresによる空間識別", 第30回日本ロボット学会学術講演会, RSJ2012AC1B2-2, 2012.</li>
                    <li>落合佑哉, 竹村憲太郎, 高松淳, 小笠原司: "移動ロボットに搭載したLIDARを用いた未知環境における移動障害物の追跡", ロボティクスメカトロニクス講演会2012(ROBOMEC2012), 1A1-M03, 2012.</li>
                    <li>近藤豊, 竹村憲太郎, 高松淳, 小笠原司: "動作の周波数領域表現に着目したBag-of-featuresに基づく類似動作分類", 第17回ロボティクスシンポジア, pp. 541-547, 2012.</li>
                    <li>桑原潤一郎，竹村憲太郎，末永剛，高松淳，小笠原司: "再利用可能なRTミドルウエアコンポーネントを利用した異種ロボット間での相互位置推定", 第12回計測自動制御学会システムインテグレーション部門講演会(SI2011)，1K4-2, 2011.</li>
                    <li>山川智久，竹村憲太郎，高松淳，小笠原司: "頭部装着型視線計測装置のための3次元環境を考慮した注視点推定法"，ヒューマンインタフェース学会シンポジウム，1211L，2011．</li>
                    <li>Emarc Magtanong, Akihiko Yamaguchi, Kentaro Takemura, Jun Takamatsu, and Tsukasa Ogasawara: Inverse Kinematics Solver for an Android Face using Neural Network, in Proceedings of the 29th Annual Conference of the Robotics Society of Japan, 1Q3-1, 2011.</li>
                    <li>佐藤志保理，山口明彦，竹村憲太郎，高松淳，小笠原司："動作の性別属性を変換する男女双方向スタイル変換フィルタ"，第29回日本ロボット学会学術講演会,1N2-5, 2011.</li>
                    <li>福間健太，竹村憲太郎，高松淳，小笠原司："特徴点のクラスタリングを用いた動的環境に頑健なカメラ位置姿勢推定"，第29回日本ロボット学会学術講演会，3I2-4, 2011.</li>
                    <li>近藤豊, 竹村憲太郎, 高松淳, 小笠原司, "ジェスチャデータベース構築のための連続ウェーブレット変換に基づく類似動作分類," 第29回日本ロボット学会学術講演会, 1F3-4, 2011.</li>
                    <li>桑原潤一路，竹村憲太郎，末永剛，高松淳，小笠原司："RTミドルウエアを利用した異種ロボット間での粒子群最適化を用いた相互位置推定"，第29回日本ロボット学会学術講演会，1B3-7，2011．</li>
                    <li>伊藤晃大，竹村憲太郎，高松淳，小笠原司："ウェアラブルインターフェースのためのアクティブ骨導音センシング"，第29回日本ロボット学会学術講演会，1B3-7，2011.</li>
                    <li>佐藤志保理，山口明彦，竹村憲太郎，高松淳，小笠原司: "任意の動作を女性らしく変化させるスタイル変換フィルタ"，ロボティクスメカトロニクス講演会2011，1A1-O11，2011.</li>
                    <li>森太一，竹村憲太郎，高松淳，小笠原司: "Bag-of-Featuresを用いた環境変化に頑健なビューシーケンスナビゲーション"，ロボティクスメカトロニクス講演会2011，1A1-M03，2011.</li>
                    <li>桑原潤一郎，竹村憲太郎，末永剛，高松淳，小笠原司: "移動ロボットのネットワーク化と制御用RTコンポーネント"，第11回計測自動制御学会システムインテグレーション部門講演会(SI2010)，2B2-3，pp.1068-1069，2010.</li>
                    <li>日永田佑介，末永剛，竹村憲太郎，高松淳，小笠原司: "L0ノルム最小化による動的環境化に適用可能なSLAM"，第11回計測自動制御学会システムインテグレーション部門講演会(SI2010)，2O1-3，pp.1648-1651，2010.</li>
                    <li>高橋健治，竹村憲太郎，末永剛，高松淳，小笠原司: "移動ロボットによるSIFTを用いた三次元特徴点地図の生成"，第28回日本ロボット学会学術講演会予稿集，RSJ2010AC1Q3-2，2010.</li>
                    <li>桑原潤一郎，竹村憲太郎，末永剛，高松淳，小笠原司: "ユニバーサルマップを利用した異種ロボットにおける位置情報共有"，第28回日本ロボット学会学術講演会予稿集，RSJ2010AC1Q1-5，2010.</li>
                    <li>伊藤晃大，竹村憲太郎，末永剛，高松淳，小笠原司: "前腕骨を伝達経路とする骨導音を利用した常時装着インタフェース"，第28回日本ロボット学会学術講演会予稿集，RSJ2010AC1C3-1，2010.</li>
                    <li>近藤豊，竹村憲太郎，高松淳，小笠原司: "多人数環境を考慮したコミュニケーションのためのボディジェスチャー生成"，第28回日本ロボット学会学術講演会，RSJ2010AC3B2-2，2010.</li>
                    <li>廣瀬駿，末永剛，竹村憲太郎，川上玲，高松淳，小笠原司: "空間的依存性を用いた屋外光源下における物体表面色の推定"，第13回画像の認識・理解シンポジウム（MIRU2010），OS9-1，2010.</li>
                    <li>桑原潤一郎，伊藤晃大，日永田佑介，竹村憲太郎，末永剛，高松淳，小笠原司: "RTミドルウェアを利用した異種ロボット間での位置情報共有"，ロボティクスメカトロニクス講演会2010，2A2-C05，2010</li>
                    <li>日永田佑介，竹村憲太郎，伊藤晃大，桑原潤一郎，末永剛，高松淳，小笠原司: "RTミドルウェアを用いた汎用移動コンポーネント群設計指針の検討"，ロボティクスメカトロニクス講演会2009，2P1-A20，2010.</li>
                    <li>上田悦子，竹村憲太郎，竹内善之，栗田雄一，小笠原司，秋元加代子: "対話ロボット身振り生成のための古典舞踊動作解析"，第10回計測自動制御学会システムインテグレーション部門講演会，pp. 618-619，2009.</li>
                    <li>竹内善之，山口明彦，竹村憲太郎，高松淳，小笠原司: "モーションキャプチャデータから多様な動作生成を可能にする運動学習プリミティブの合成"，第10回計測自動制御学会システムインテグレーション部門講演会，pp.824-827，2009.</li>
                    <li>竹村憲太郎，荒木天外，怡土順一，松本吉央，高松淳，小笠原司: "測域センサ搭載型ロボットのための汎用三次元環境地図の利用"，第27回日本ロボット学会学術講演会予稿集，1F3-01，2009.</li>
                    <li>松永典之，竹村憲太郎，高松淳，小笠原司: "歩行者の軌跡情報を用いた屋外ナビゲーション"，第27回日本ロボット学会学術講演会予稿集，2Q2-02，2009.</li>
                    <li>末永剛，竹村憲太郎，松本吉央，高松淳，小笠原司: "動・作業知能のための視覚に基づくロバストな知能モジュール群の開発 -位置推定と再利用へ向けた通信支援-"，第27回日本ロボット学会学術講演会予稿集，2D2-02，2009.</li>
                    <li>近藤豊，竹村憲太郎，高松淳，小笠原司: "再構成可能な動作データベースに基づく柔軟なインタラクション動作のオンライン生成"，第27回日本ロボット学会学術講演会予稿集，1L3-05，2009</li>
                    <li>廣瀬駿，怡土順一，竹村憲太郎，川上玲，高松淳，小笠原司: "画像ノイズを考慮した屋外光源下における物体表面色の推定"，画像の認識・理解のシンポジウム2009，OS9-1，2009.</li>
                    <li>近藤豊，怡土順一，竹村憲太郎，高松淳，小笠原司: "マルチスレッドに対応した動作計画コンポーネント"，ロボティクスメカトロニクス講演会2009，2A2-C14，2009.</li>
                    <li>松永典之，山城容一朗，荒木天外，怡土順一，竹村憲太郎，松本吉央，高松淳，小笠原司: "照明変化に頑健な天井ビューシーケンスナビゲーション"，ロボティクスメカトロニクス講演会2009，2P1-F20，2009.</li>
                    <li>末永剛，竹村憲太郎，高松淳，小笠原司: "RTコンポーネント間の柔軟なデータ通信支援ツール"，ロボティクスメカトロニクス講演会2009，2A2-C02，2009.</li>
                    <li>山城容一朗，怡土順一，竹村憲太郎，松本吉央，高松淳，小笠原司: "屋内外環境のためのビューシーケンスナビゲーションの拡張"，第14回ロボティクスシンポジア，2D1，pp.223-228，2009.</li>
                    <li>里村卓哉，竹村憲太郎，中村善一: "移動ロボットの遠隔操作における画像提示法の評価"，電子情報通信学会関西支部学生会第14回学生会研究発表講演会，D8-6，p.123，2009.</li>
                    <li>小橋優司，末永剛，竹村憲太郎，高松淳，小笠原司: "頭部装着型視線計測装置のための自然特徴点を用いた三次元注視点計測"，電子情報通信学会技術研究報告書ヒューマン情報処理，HIP2009-74，pp.5-10，2009.</li>
                    <li>荒木天外，山城容一朗，怡土順一，竹村憲太郎，松本吉央，高松淳，小笠原司: "ユニバーサルマップを利用したビューシーケンスの生成とナビゲーション"，第9回計測自動制御学会システムインテグレーション部門講演会，pp.347-348，2008.</li>
                    <li>河村雅人，怡土順一，竹村憲太郎，松本吉央，高松淳，小笠原司: "視線方向知覚を考慮したアンドロイドの頭部眼球動作"，第9回計測自動制御学会システムインテグレーション部門講演会，pp.1019-1020，2008.</li>
                    <li>山本和樹，上田悦子，末永剛，竹村憲太郎，松本吉央，高松淳，小笠原司: "ピアノ演奏における手指動作の自動生成 -MusicXMLを入力とした3DCGアニメーション-"，第13回日本バーチャルリアリティ学会大会論文集，1A5-5，2008.</li>
                    <li>山城容一朗，怡土順一，竹村憲太郎，松本吉央，高松淳，小笠原司: "移動ベクトルによる屋外ビューシーケンスナビゲーション"，第26回日本ロボット学会学術講演会予稿集，1H3-04，2008.</li>
                    <li>浅野慧，末永剛，竹村憲太郎，松本吉央，高松淳，小笠原司: "複数カメラの観測統合による広範囲な顔・視線計測"，第7回情報科学技術フォーラム，pp.485-486，2008.</li>
                    <li>荒木天外，怡土順一，竹村憲太郎，栗田雄一，松本吉央，小笠原司: "画像に基づくナビゲーションのための３次元環境地図の構築"，ロボティクスメカトロニクス講演会2008，2P2-C15，2008.</li>
                    <li>小林純也，栗田雄一，末永剛，竹村憲太郎，松本吉央，小笠原司: "位置情報を基にした組織内人物間の親密度の視覚化"，ロボティクスメカトロニクス講演会2008，1A1-D17，2008.</li>
                    <li>吉村崇，竹村憲太郎，松本吉央，小笠原司: "遠隔講義における学習者の筆記行動推定"，情報処理学会関西支部大会，pp.139-142，2007．</li>
                    <li>小林純也，末永剛，竹村憲太郎，栗田雄一，松本吉央，小笠原司: "室内における動線情報を用いた個人識別"，情報処理学会関西支部大会，pp.67-70，2007．</li>
                    <li>小林純也，末永剛，竹村憲太郎，栗田雄一，松本吉央，小笠原司: "人物の動線情報を用いた個人識別手法"，第25回日本ロボット学会学術講演会予稿集，2O13，2007.</li>
                    <li>竹村憲太郎，末永剛，松本修，松本吉央，小笠原司: "移動ロボットによる屋内ウォークスルー環境の自動構築"，ロボティクスメカトロニクス講演会2007，2A2-B10，2007.</li>
                    <li>松本修，末永剛，竹村憲太郎，松本吉央，小笠原司: "環境と強調するサービスロボットの開発-環境カメラとの協調による自己位置推定-"，情報処理学会関西支部大会環境知能研究会，pp.153-156，2006．</li>
                    <li>井垣宏，三井康平，竹村憲太郎，玉田春昭，中村匡秀，松本健一，松本吉央: "注視情報に基づくネットワーク家電の状態提示システムの構築"，電子情報通信学会技術研究報告，Vol.105，No.628，pp.061-066，2006.</li>
                    <li>松本修，末永剛，竹村憲太郎，松本吉央，小笠原司: "環境と協調するサービスロボットの開発"，第7回計測自動制御学会システムインテグレーション部門講演会，3N1-5，2006.</li>
                    <li>吉村崇，竹村憲太郎，松本吉央，小笠原司: "ビデオ講義における受講者の行動計測・状態推定システムの提案"，ヒューマンインタフェースシンポジウム2006，1342，2006.</li>
                    <li>竹村憲太郎，松本吉央，小笠原司: "ミーティングにおける注意計測システムの構築"，FIT2005第4回情報科学技術フォーラム，pp.517-518，2005．</li>
                    <li>松本吉央，竹村憲太郎，上田悦子，小笠原司: "顔・注視点計測を用いた知的コンピュータインタフェース"，情報処理学会コンピュータビジョンとイメージメディア研究会研究報告CVIM-150(IPSJ-SIG-CVIM-150)，pp.33-38，2005.</li>
                    <li>竹村憲太郎，南出隼人，松本吉央，小笠原司: "複数コンピュータ環境における注視行動に基づく操作対象の切り替え"，ヒューマンインタフェースシンポジウム2004，pp.1149-1152，2004．</li>
                    <li>末永剛，竹村憲太郎，松本吉央，小笠原司: "視点位置計測を用いた半透明3次元ディスプレイ"，ヒューマンインタフェースシンポジウム2004，pp.939-942，2004．</li>
                    <li>竹村憲太郎，松本吉央，小笠原司: "ミーティングにおける複数人の視線計測に基づく共同注意の撮影"，画像認識・理解のシンポジウム(MIRU2004)，pp.I-445-450，2004.</li>
                    <li>竹村憲太郎，松本吉央，小笠原司: "複数人の視線計測に基づく「場の注意」の推定"，情報処理学会ヒューマンインタフェース研究会研究報告HI-110(IPSJ-SIG-HI-110)，pp.25-30，2004.</li>
                    <li>竹村憲太郎，松本吉央，小笠原司: "非侵襲ドライバ行動計測に関する研究-注視点の計測注視対象の判別-"，ロボティクス・メカトロニクス講演会’03講演論文集，R03426-86，1A1-2F-E4，2003.</li>
                    <li>竹村憲太郎，怡土順一，松本吉央，小笠原司: "ドライバ注視点計測システム"，日本ロボット学会創立20周年記念学術講演会予稿集，3C17，2002.</li>
                    <li>乗松泰明，竹村憲太郎，中村善一: "全方位移動ロボットの全方位視覚に基づくナビゲーション"，電気学会システム・制御研究会，SC-01-20~30，pp.25-29，2001.</li>
                </ol>
            </details>                    
     <footer class="bg-gray-400 text-white text-center py-4 mt-10">
        <p>&copy; Human Sensing Group 2025</p>
    </footer>

    <script>
        // JavaScriptでheader.htmlを読み込む
        fetch('header.html')
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.text();
            })
            .then(data => {
                document.getElementById('header-placeholder').innerHTML = data;

                // ハンバーガーメニューの開閉を制御
                const menuToggle = document.getElementById('menu-toggle');
                const mobileMenu = document.getElementById('mobile-menu');
                if (menuToggle && mobileMenu) {
                    menuToggle.addEventListener('click', () => {
                        mobileMenu.classList.toggle('hidden');
                    });
                }
            })
            .catch(error => console.error('Error loading header:', error));
    </script>
</body>
</html>
